to use mongo shell in docker: docker exec -it mongodb-database /bin/sh 
-- mongodb-database is the container name

- either don't have any environment variables in docker compose file if we don't want to make it secure
- else use command: mongo admin -u siddhant -p 'dbpass' 
- or use command: mongo admin -u uname -p 'password' --authenticationDatabase admin
- where uname and password should match what is given in docker compose file
- same can be checked using 'env' command since they're environment variables

mongodb is no sql database 
- non relational  database
- document based

type of nosql database:
    - document based
    - key-value based
    - wide-column database
    - graph database

- type 'mongo' in unix shell to open mongo shell and exit() to exit mongo shell
- 'show dbs' command in mongo shell to see list of databases and space they have occupied
    -- if we create any new database it will not show in list of databases (by showdbs) 
        until it has atleast 1 document
- use siddhantdb -- to create a new database and start using it
- db -- to check which database is being currently used
- db.createCollection('FacebookComments') -- to create a new collection in currentl database
- db.instagramComments.insert({username:'siddhant_jain5', post_id:'instagram.com/ab4df', comment:'good'})
    -- 2nd way of creating table <- we directly insert a record in the table and if table is not present,
        it will create the table and insert the record
-- always prefer first way (createCollection command), we can provide additional paramerters in that
- db.createCollection(collection_name, {capped:true, size:5242880, max:5})
    -- capped true means that this collection can have maximum of 5 documents or less
    -- and maximum size cannot exceed 5242880 
    -- if it reaches in 4 documents then only 4 documents will be there
    -- if it reaches in 6 documents then 5 documents will be there

mongodb has two type of documents
- relational documents
- embedded documents (preferred)(better for scalability)

- db.student.insert({regNo: "1234",name: "student1", course: {courseName: "MCA", duration: "3 years"},address: { city: "bangalore", state: "KA", country: "India"}})
-- here couse and address are embedded documents
-- both of them do not have any primary key of their own and are dependent on student object

- mongodb create a unique objectId for each document which is nothing but a primary key (key="_id)
- we can override and mention our own primary key by providing value to _id key
- db.student.insert({_id: "5678", regNo: "5678",name: "student2", course: {courseName: "MCA", duration: "3 years"},address: { city: "bangalore", state: "KA", country: "India"}})
- _id is the only key which is used as primary key, we can't provide any other 

-- to do bulk insert write following in mongo shell
var bulkDocuments = [{username:'siddhant_jain5', post_id:'instagram.com/ab4df', comment:'good'}, {username:'insta_user', post_id:'instagram.com/avg75v', comment:'better'}, {username:'fb_user', post_id:'instagram.com/kjnrke', comment:'best'}]
db.FacebookComments.insert(bulkDocuments)
var bulkDocuments2 = [{username:'siddhant_jain6', post_id:'instagram.com/ab4df', comment:'good'}, {username:'quora_user', post_id:'instagram.com/avg75v', comment:'better'}, {username:'linkedin_user', post_id:'instagram.com/kjnrke', comment:'best'}]
db.FacebookComments.insert(bulkDocuments2)

-- update records in mongodb
- db.FacebookComments.update({comment:"good"},{$set:{"comment":"more than good"}})
-- when we use update, it only changes 1 record even if multiple documents satisfy the condition
-- it starts from top, updates the first document with matching condition and the stops

- db.FacebookComments.update({comment:"better"},{$set:{"comment":"all better"}}, {multi:true})
-- {multi:true} will change all records matching the condition

-- upsert in mongodb
- db.FacebookComments.update({comment:"better"},{$set:{"comment":"all better"}}, {upsert:true})
-- if it finds a record with comment "better" it updates that record
-- else it create a new record with just one key:value i.e. what we mentioned in set command

-- delete document in mongodb
- db.FacebookComments.remove({"comment":"all better"})
-- remove command will remove all records (unlike update command)

- show collections -- to get list of collections in current database
- db.instagramComments.find() -- to list all records in a collection
- db.instagramComments.find().pretty() -- to format documents properly like a json

-- to query documents based on some condition
- db.FacebookComments.find({comment:"best"})
-- it will return all the records which match the condition
-- if we give any key which is not in documents then it will give empty result and not error
    bcz it is nosql so no fixed schema, key can be present in one doc and not present in another

db.FacebookComments.find().limit(2)
-- to limit number of records displayed (first 2 records will be shown)

--sort the records
db.FacebookComments.find().sort({username: -1})
-- -1 will sort it in descending order
-- 1 will sort in ascending order

-- search based on embedded column
db.student.find({"address.city": "bangalore"})

-- find all students with student ids between a range
- db.student.insert({regNo: "1240",name: "student3", course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student.insert({regNo: "1284",name: "student4", course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student.insert({regNo: "1354",name: "student5", course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student.insert({regNo: "5234",name: "student6", course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})

- db.student.find({regNo: {$gt: "5000"}}) -- get all record will regNo greater than(gt) 5000 
    -- since input is a string if we provide 5000 without quotes in query, it will not return anything
- db.student.find({regNo: {$lt: "5000"}})
- db.student.find({regNo: {$in: ["1240","1340"]}}) -- only records which have regNo as either 1240 or 1340
- db.student.find({regNo: {$gt: "1240", $lt:"1354"}}) -- boundaries exclusive (1240 and 1354 will not be in o/p)

-- indexing in mongodb
- db.student_new.insert({regNo: "1234",name: "student1", section:"F4", course: {courseName: "MCA", duration: "3 years"},address: { city: "bangalore", state: "KA", country: "India"}})
- db.student_new.insert({regNo: "5678",name: "student2", section:"F2", course: {courseName: "MCA", duration: "3 years"},address: { city: "bangalore", state: "KA", country: "India"}})
- db.student_new.insert({regNo: "1240",name: "student3", section:"F4", course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student_new.insert({regNo: "1284",name: "student4", section:"F2", course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student_new.insert({regNo: "1354",name: "student5", section:"F4", course: {courseName: "MCA", duration: "3 years"},address: { city: "jaipur", state: "UP", country: "India"}})
- db.student_new.insert({regNo: "5234",name: "student6", section:"F2", course: {courseName: "MCA", duration: "3 years"},address: { city: "jaipur", state: "UP", country: "India"}})
- db.student_new.explain("executionStats").find({section: "F4"})
-- under executionStats there is a key called totalDocsExamined: its value is 6 
    -- which is total number of records in the collection right now
-- if there are millions of records, then it will go through all million records to search for given criteria

- db.student_new.createIndex({section: 1})
 -- to apply index on section key,and 1 to have it in ascending order
 -- this will add another index, and not remove current indexes
 -- since before it was 1, if we run getIndexes now it will give 2
 -- now executionStats command will show totalDocsExamined value as 3 
    -- which is no. of rec having this value

- db.student_new.dropIndex("section_1")
 -- if we check in getIndexes this will be mentioned as name
 -- first is the key name followed by underscore followed by ascending or descending
 -- if we just say key name it will throw error saying index not found

-- aggregations in mongodb
$project -> to select specific fields
$match -> filter operation
$group -> aggregation operation
$sort -> sort operation
- db.student_new.aggregate([{"$match": {$and: [{"section":"F4"}, {"regNo":{"$gt":"1239"}}]} }])
- db.student_new.aggregate([{"$project":{"name":1, "section":1, "address.city":1}}])
    -- if we mention 1 it will be displayed and if we mention 0 then not displayed
    -- we can also skip the columns we don't want to select
    -- for _id column we explicitly need to mention 0 otherwise it will be displayed

- db.student_new.aggregate([{"$project":{"name":1, "section":1, "address.city":1, "_id":0}}])
- db.student_new.aggregate([{"$match": {"section":"F4"}}, {"$project":{"name":1, "section":1, "address.city":1, "_id":0}}])

-- group by aggregations
- db.student_marks.insert({regNo: 1234,name: "student1", section:"F4", marks:80.5, course: {courseName: "MCA", duration: "3 years"},address: { city: "BLORE", state: "KA", country: "India"}})
- db.student_marks.insert({regNo: 5678,name: "student2", section:"F2", marks:70.5, course: {courseName: "MCA", duration: "3 years"},address: { city: "BLORE", state: "KA", country: "India"}})
- db.student_marks.insert({regNo: 1240,name: "student3", section:"F4", marks:65, course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student_marks.insert({regNo: 1284,name: "student4", section:"F2", marks:92.5, course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student_marks.insert({regNo: 1354,name: "student5", section:"F4", marks:41.2, course: {courseName: "MCA", duration: "3 years"},address: { city: "jaipur", state: "RAJ", country: "India"}})
- db.student_marks.insert({regNo: 5234,name: "student6", section:"F2", marks:33, course: {courseName: "MCA", duration: "3 years"},address: { city: "jaipur", state: "RAJ", country: "India"}})
- db.student_marks.insert({regNo: 1235,name: "student7", section:"F4", marks:35, course: {courseName: "MCA", duration: "3 years"},address: { city: "BLORE", state: "KA", country: "India"}})
- db.student_marks.insert({regNo: 5676,name: "student8", section:"F2", marks:95, course: {courseName: "MCA", duration: "3 years"},address: { city: "BLORE", state: "KA", country: "India"}})
- db.student_marks.insert({regNo: 1236,name: "student9", section:"F4", marks:48, course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student_marks.insert({regNo: 1237,name: "student10", section:"F2", marks:12, course: {courseName: "MCA", duration: "3 years"},address: { city: "jhansi", state: "UP", country: "India"}})
- db.student_marks.insert({regNo: 1338,name: "student11", section:"F4", marks:48, course: {courseName: "MCA", duration: "3 years"},address: { city: "jaipur", state: "RAJ", country: "India"}})
- db.student_marks.insert({regNo: 5239,name: "student12", section:"F2", marks:100, course: {courseName: "MCA", duration: "3 years"},address: { city: "jaipur", state: "RAJ", country: "India"}})

- db.student_marks.aggregate([{"$group":{"_id": {"section": "$section"}, "TotalMarks":{"$sum": "$marks"}}}])
    -- id is compulsory in group by
- db.student_marks.aggregate([{"$group":{"_id": {"section": "$section"}, "TotalMarks":{"$sum": "$marks"}, "Count":{$sum:1}, "AverageMarks":{$avg: "$marks"}}}])
- db.student_marks.aggregate([{$match:{section: 'F4'}},{"$group":{"_id": {"section": "$section"}, "TotalMarks":{"$sum": "$marks"}}}])

- db.student_new.getIndexes() --> go get which key is current index, by default '_id'
- db.student.count() --find number of documents in a collection

- all mongodb database are stored in /data/db folder
- table in sql is collection in mongodb
- row in sql is document in mongodb (single record)

-- replication in mongodb
-- replication and high availability are main features of mongodb
-- they come inbuilt with mongodb and no separate s/w installation is required
-- replication done with master(one)-slave(many) architecture
-- can me done using mongodb atlas
-- in atlas we can create one free cluster (which is by default 3 node cluster)
-- one primary node and two secondary
-- we can insert record only in primary node and read from secondary also
-- we need to provide network access and database access in atlas

--------------------------------------------------------------------
-- mongo db stores bson (which are binary json)
-- max document size in mongodb can be 16mb
-- mongodb doesn't enforce any foreign key relationship
    -- there can be soft foreign keu relation ship
    -- like book collection can have publisherid key
    -- and there can be a separate publisher collection where we can get all info 
        -- of a publisher using the publisherid
    -- but no rules like publisherkey should be mandtorily be present in
        -- publisher collection are enforced by mongodb (we need to take care of that)
-- any table which is a dependent of another table can be an embedded document
    -- for eg. rating is dependent on books or address is dependent on customers
    -- these documents(rating/address) have no meaning by themselves
    -- these do not need to be separate collection in mongodb
    -- they can be a document or array of documents inside the collection they're dependent on
    -- this saves us from performing several joins to get this data
    -- drawback is it's a bit of overhead if we mostly don;t require ratings info with books
-- when to use embedded documents
    -- check if embedded doc is wanted 80% time or not?
        -- for eg. if we are displaying books on e-commerce website where we displayed
            ratings everytime, then we should keep it as an embedded document
        -- suppose on a page the user only sees the list books that he has purchased
            and doesn't require ratings since it is already purchased. then no a good
            idea to go with embedded documents.
    -- is embedded data a bounded set?
        -- for eg rating will keep growing for a book as the site and the book 
            gain popularity. so as more people rate the document will keep getting bigger 
            and bigger and hence will not be a good idea to embed it
            it might surpass 16mb size at some point which is not possible in mongodb
        -- but if that embedded doc size if limited than fine, like a customer might have 
            max of 2-3 addresses
    -- how varied are your queries?
        -- for eg. if a query is normal like get all list of books with its ratings, then 
            embedded documents is a good idea
        -- but if they're different type of queries, then data modelling should differ
    -- whether it's integration db or application db
        -- application db is which we use for a small scale application. where each application
            has a single db associated to it.
        -- integration db are used by large enterprise, where lot of different application
            use the same db
        -- all application should agree with the defined data model
        -- easier to design data for application db

- video course on mongodb and ODM (object document mapper) similar to ORM
    https://www.youtube.com/watch?v=E-1xI85Zog8
- Udemy course of the exact same vide (broken into lesson)(enrolled in udemy account)
    https://www.udemy.com/course/draft/1358396/learn/lecture/8222114?start=0#overview
- github repo of the above video:
    https://github.com/mikeckennedy/mongodb-quickstart-course/tree/master/src/snake_bnb/src

check for $elemmatch $gte $lte 

-----------------------------------------------------------------------------------------

##### from udemy course #####

mongod is the database server, it should always be running if we want to connect to it
by default it runs on port 27017, we can change it by adding --port to mongod command
same --port can be used with mongo command to open shell and connect it to server
in windows it runs as a service in background and we don't need to manually run it
but in linux and mac we need start it manually and keep it running as long as we want to access it
the command for it is: mongod
it looks for /db/data path in root folder or c/users_username (windows), 
    if path is not present it fails to start
if we want to store db in a different path then command is: mongod --dbpath "path of /db/data"

difference b/w update and (updateOne or updateMany):
    -- in updateOne or updateMany it is compulsory to pass a operator,
    -- if we try without any operator for eg. $set, it will throw error
    -- but with update it will simply create a new document with field passed
        and relace it with existing document (objectId of all the replaceed documents will be same) 
    -- for eg there are two documents {_id:1, name: random1, salary: 5},{_id:2, name: random2, salary: 10}
        and we write update query like db.emp.update({name:random2}, {age15})
        expectation is {_id:1, name: random1, salary: 5, age:15}, but it will become {_id=1, age=15}
        correct way of doing was db.emp.update({name:random2}, {$set: {age15}})
    -- so better to use updateOne and updateMany
    -- simple update command can work like replace, but there is different func for replace also

find doesn't return a array of documents as it looks like
instead it sends a cursor object (which has lot of metadata)
bcz data can be huge so sending all at once can be very costly
to get as array
- db.student_new.find().toArray()
.pretty() is a cursor function as hence will not work with commands which return
a document or array of documents (eg. findOne())


data types in mongodb:
- text (enclosed with double quotes/ single quotes)
    - no limitation on individual text (but total document size should not exceed 16mb)
- booleans (true/false)
- numbers (32bit), numberLong(64 bit), numberDecimal (in shell, everything by default is 64bit float)
- objectId (special data to indentify a mongodb document uniquely)
- ISODate (store date objects) (new Date() in shell gets current date in date'T'time'Z' format)
- Timestamp (a long number based on current time in milliseconds) 
    (new Timestamp() in shell gets current date)
- embedded documents
- Arrays (of any of the above datatypes)

eg.
{name: "Dunzo", isStartup: true, employees: 33, funding:1234567890124567890, 
details:{ceo "unknown", launched:2020}, tags: [{title:"deivery"}, {title:"e-commerce"}],
foundingDate: new Date(), insertedAt: new Timestamp()
}
-- in above funding number will get truncated
-- so storing in string can b good idea

{a: NumberInt(1)} this will be lesser in size than {a: 1}
bcause former is Int32 and later is float64

- relation is mongodb
    -- to establish relation between two kind of documents
        eg. customer collection and address collection
        or customer collection and branches visited collection
    -- two ways to establish relation
        - embedded document (inside customer we can have address document or list of 
            address documents)
        - references
            - embedding doesn't work in all cases. It works for address bcz an address mostly will be
                associated with 1 or very few customers
            - but in case of branch visited, one brnch will be visited by many customers, so our
                data will contain lot of duplicates since all of data for a single branch will be stored
                with all customers visiting it
            - and if any of branch data changes, then we need to change it for all customers who ever 
                visited
            - so for references we only store id of branch and have a separate branch collection 

    eg. of references
    - db.patientdb.insertOne({name: "Max", age:29, diseaseSummaryId: "max-summary-1"})
    - db.diseaseSummaries.insertOne({_id: "max-summary-1", diseases: ["cold", "broken-leg"]})

    -- to combine both (2 steps)
    - db.patientdb.findOne({name: "Max"})
    - var dsid = db.patientdb.findOne({name: "Max"}).diseaseSummaryId
    - db.diseaseSummaries.findOne({_id = dsid})

    -- in this example, embedded document will be better (one to one relationship)
        -- if we're building a web app where we need to render both info
        -- but reference document will be better for a analytical use case 
            -- since we might need to analyse diseases alone, without info of patient

    -- relation for questions-answers thread (one to many relationship)
        -- one ques can have many answers, but one answer is for one ques only
        -- for such use case, embedded document is better
        -- in document which is on 'one' side (question) can embed 'many' side document (answers)

    -- relation for city-citizen (one to manny relationship)
        -- one city will have many citizens, but citizen can live in only one city
        -- if we use embedded doc, city document size might hit 16mb limit for very
            populated cities like Mumbai, delhi
        -- we get lot of useless citizen data if we just want to analyse city data
        -- for such use cases, references are better
        -- with each citizen, we can store the cityId, bcz if we store citizens with city
            the array will contains millions of elements
    
    -- relation for orders (customers-products) (many to many relationship)
        -- for such use cases, references is better
        -- we can have products collection and customers collection
        -- and then we can have order collection with customerid and productid
        -- or better we can store list of orders in customer collection 
        -- each element of order array can have an embedded document productid and quantity

        -- we can use embedded data with only one problem, lot of duplication
        -- so if we need to change a product, it has to be changed for all customer who brought it
        -- but if in the use case, even if product is updated, the record doesn't need to change
            bcz it maintains the snapshot of details while placing order, then embedded can be considered

    -- $lookup
        -- db.books.aggregate([{$lookup: {from: "author_collection", localField: "authors",
        foreignField: "_id", as:"creators"}}])
        -- used to join author collection with books collection
        -- will match "authors" column from books to "_id" column from authors
        -- it will have all existing keys along with new key "creators" having 
            author collection objects
        -- useful with references

assignment: user -> create/edit/delete/fetch one/ fetch many/ comments on : post
identify nd create mongodb collections and relations and way to store relation

### my solution 
collections -> users, posts, comments (correct based on video solution)
relations
user -> post (one to many)
post -> comments (one to many) (embedded) (correct based on video solution)
user -> comment (one to many) (reference) (correct based on video solution)

user: {userId, username, age, email} (correct based on video solution)
post: {postId, title, postContent, tags, 
        author(userId), comment : { userId, commentContent}} (correct based on video solution)

-- schema validation
db.createCollection("postsCollection", {
    validator: {
        $jsonSchema: {
            bsonType: "object",
            required: ["title", "text", "author", "comments"],
            properties: {
                title: {
                    bsonType: "string",
                    description: "must be a string and is requried"
                },
                text: {
                    bsonType: "string",
                    description: "must be a string and is requried"
                },
                author: {
                    bsonType: "objectId",
                    description: "id from user collection"
                },
                comments: {
                    bsonType: "array",
                    description: "array of comments on post, can be empty array",
                    item: {
                        bsonType: "object"
                        required: ["commentContent", "author"]
                        properties: {
                            commentContent: {
                                bsonType: "string"
                                description: "actual comment made my a user"
                            },
                            author: {
                                bsonType: "objectId",
                                description: "id from user collection"
                            }
                        }
                    }
                }
            }
        }
    }
})

-- using above validation if we pass a wrong value, insertion fails and document is not inserted
-- to modify validation of already crated collection
db.runCommand({collMod: "postsCollection", 
    validator: {
        $jsonSchema: {
            bsonType: "object",
            required: ["title", "text", "author", "comments"],
            properties: {
                title: {
                    bsonType: "string",
                    description: "must be a string and is requried"
                },
                text: {
                    bsonType: "string",
                    description: "must be a string and is requried"
                },
                author: {
                    bsonType: "objectId",
                    description: "id from user collection"
                },
                comments: {
                    bsonType: "array",
                    description: "array of comments on post, can be empty array",
                    item: {
                        bsonType: "object"
                        required: ["commentContent", "author"]
                        properties: {
                            commentContent: {
                                bsonType: "string"
                                description: "actual comment made my a user"
                            },
                            author: {
                                bsonType: "objectId",
                                description: "id from user collection"
                            }
                        }
                    }
                }
            }
        }
    },
    validationAction: "warn"
})

default validationAction is "error"

-- mongodb shell and server
-- dbpath is where actual mongodb data get written and --logpath is where logs get written

-- command to start mongo server with these configured
- mongod --dbpath 'path to folder to store db'  --logpath 'path to folder to store logs/logFileName.log'
-- for log folder we also need to provide a path to log file where to write it (not necessary to create
    it beforehand)

-- mongodb by default uses 'WiredTiger' as storage engine but we can change it

-- fork option (ony runs with mac and linux)
-- import to give logpath when running fork command
- mongod fork --logpath 'path to folder to store logs/logFileName.log'
-- now it will run as a service in background, and not block the cmd prompt
-- in windows, we have option to run it as a service (same as fork), which we 
    select while installation
-- command in windows: net start mongodb
-- to shutdown this service running in background:
-- in mongo shell type
- use admin
- db.shutdownServer()
-- this works in windows as well, alternatively in windows we can also use
- net stop mongodb

-- we can create a config file with all these options (so it is saved for future)
-- .cfg extension, look more in documentation
-- how to use it config file
- mongod -f 'path to config file'

-- create operation in details

- db.collection_name.insertOne({name: "sid", age: 25, hobbies: ["tv-series", "books"]})
-- this will automatically create an id with field name _id and type ObjectId

- db.collection_name.insertMany([{name: "ravi", age: 26, hobbies: ["tv-series", "movies"]},
 {name: "sowmya", age: 24])
 -- id will be created automatically for all the documents

-- insertOne takes a document as an argument (enclosed in {})
-- insertMany takes a list of documents as an argument (enclosed in [])
-- we can't simply pass ',' separated documents to insertMany as argument

- db.insert({name: "ritik", age:25})
- db.insert([{name: "Utkarsh", age:24}, {name: "Rana", age:26}])
-- insert can be used for one or many records

-- INSERT VS INSERTONE/INSERTMANY
-- insertOne and insertMany return back the id of newly created document which insert does not
-- when we create an application, we generally want tp return its id for further use
-- but with insert it is ineffecient bcz we have to wait for insertion to complete and the 
    query the entire collection again

-- create custom id instead of using auto-generated ids
-- we can explicitly mention '_id' field in each document
-- if we pass any duplicate id which is already present in the collection,
    then insert operation will fail and we'll get the error msg

-- ORDERED_INSERT: if we are bulkInserting (insertMany), then all documents before the duplicate
    was encountered will be added, but all other after the duplicate will fail 
    (even if they're correct) ...... This is the default behaviour of MongoDb, but can be changed
-- we can change the ORDERED_INSERT behaviour in insertMany
- db.collection_name.insertMany([{}, {}, {}], {ordered: false})
-- UNORDERED_INSERT after passing list of documents, we can pass a document of arguments
    in this case we have one argument, 'ordered' value of which by default is true,
    but we're setting it to false. So all the documents will be tried to insert, even if any
    of them fails. So we can have multiple failed documents as well as inserted documents

-- in any of the case, a ROLLBACK will not happends, i.e. whatever got inserted before failed document
    won't be implicitly removed from db on encountering a failed document

-- WRITECONCERN (writeConcern) => {w: 1, j:undefined}
-- w means write and number (it's value) is the number of instances of server we want
    it acknowledged
-- j stands for the journal (like a todo list)
-- we get acknowledged true msg bcz we have set w to 1

-- ATOMICITY
-- suppose there is a document with multiple fields and when writing it to the server
    write operation fails after writing some fields. If operation is not atomic, then we
    can have a partially written document in the database. But MongoDb gurantees ATOMICITY
    and hence a document would either be completly written or completly failed (done using rollback)
-- in case of bulk insert, atomicity is still at document level and not operation level
    
-- IMPORTING DATA
- mongoimport filepath_in_local_machine.json -d database_name -c collection_name --jsonArray --drop
-- if database or collection not present they'll created while running the command
-- json file can contain single document or array of multiple documents. By default command assumes
    it a single document. To specify otherwise, we use --jsonArray
-- by default if appends these documents, if collection already exists, but we can drop the 
    existing collection and create a new one with these documents using --drop

eg. mongoimport tv-shows.json -d siddhant -c tvshows --jsonArray --drop -u "admin" -p "pass" --authenticationDatabase admin
     
# methods, filters and operators in mongodb
-- each command starts with db followed by collection_name then method name
-- so commands like insertOne, find, update are all different methods
-- methods can contain documents as arguments
-- a document inside method can simply be data or filter
eg. db.collection_name.find({age:32})
-- inside find method we passed a document which contains a filter that age should be
    equal to 32

-- there can be more complex filters:
eg. db.collection_name.find( {age: {$gt: 30}} )
-- here $gt is an operator (greater than) [it is a range operator]
-- all operators starts with a '$'

-- type of operators
    -- query (eg. $eq) & projection (eg. $, $elemmatch, $meta, $slice) operators
    -- update (eg. $inc)
    -- query modifiers (depricated)
    -- aggregations


# query selectors
to check all operators, go to mongodb docs -> mngodb server -> reference -> operators

# COMPARISON OPERATORS 
$eq -> db.tvshows.find({ runtime: {$eq: 60} })
    -- eq is the defaulte comparison oprator and hence we can simply write: 
        db.tvshows.find({runtime: 60})
$gt -> db.tvshows.find({ runtime: {$gt: 60} })
$gte -> db.tvshows.find({ runtime: {$gte: 60} })
$ne (not equal) -> db.tvshows.find({ runtime: {$ne: 60} })
$lt (less than) -> db.tvshows.find({ runtime: {$lt: 60} })
$lte (less than equal) -> db.tvshows.find({ runtime: {$lte: 60} })
$in (value in mentioned array) -> db.tvshows.find({runtime: {$in: [30,42,73]}})
$nin (not in (opposite of $in)) -> db.tvshows.find({runtime: {$nin: [30,42,73]}})

-- can be used with embedded field as well
-- we need to mention field in double quotes (otherwise it is considered invalid)
db.tvshows.find({"rating.average": {$gt: 7}}).pretty()

-- using operator with Arrays
-- find document where genre is "Drama" (case sensitive)
db.tvshows.find({genres: "Drama"}).pretty()
-- finding documents with exactly matching array (only contains drama)
db.tvshows.find({genres: ["Drama"]}).pretty()

# PRETTY and COUNT
.pretty() -> adding this at end prints it formatted with nested look
.count() -> adding this at end prints returns the no. of docs to be rturned by the query preceding it


# LOGICAL OPERATORS
$or -> eg. finding all docs with rating less than 5 or more than 9.3
    - individual queries
    db.tvshows.find("ratings.average": {$lt: 5})
    db.tvshows.find("ratings.average": {$gt: 5})
    - combining both queries
    db.tvshows.find({$or: [{"rating.average": {$lt: 5}}, {"rating.average": {$gt: 9.3}}]}).count()

$nor -> neither of the conditions are met
    db.tvshows.find({$nor: [{"rating.average": {$lt: 5}}, {"rating.average": {$gt: 9.3}}]}).count()

$and -> db.tvshows.find({$and: [{"rating.average": {$gt: 9}}, {genres: "Drama"}]})
    Note: genres containing drama and not genres exactly equal to drama
    -- $and is the default logical operator so we can simply write it as:
    db.tvshows.find({"rating.average": {$gt: 9}, genres: "Drama"})
    -- this default way will not work when we have multiple condition on same column 
    -- bcz some drivers (eg. javascript) don't allow duplicate keys in their dictionary
    -- and also last condition on same key replaces all the previous ones (in all drivers)
    eg. db.tvshows.find({genres: "Drama", genres: "Horror"})
    is equivalent to db.tvshows.find({genres: "Horror"})

$not -> db.tvshows.find({runtime: {$not: {$eq: 60}}}).count()
    -- easier way to write this would be simply db.tvshows.find({runtime: {$ne: 60}}).count()

# ELEMENT OPERATORS
$exists -> find all documents where the field exists/doesn't exists 
    db.collection_name.find({field_name: {$exists: true}})
    -- can be combined with other filters as well
    db.collection_name.find({field_name: {$exists: true, $gt: 30}})
    -- if any document has the field but value is null, then also it will show in (exists: true)
    -- to eliminate null values add additional filter
    db.collection_name.find({field_name: {$exists: true, $ne: null}})

$type -> find documents wher field contains value of specific data type
    db.collection_name.find({field_name: {$type: "number"}})
    -- we can give array of datatypes, any one of which if satisfies, the doc wil be displayed
    db.collection_name.find({field_name: {$type: ["doble", "string"]}})

# EVALUATION OPERATORS
$regex -> to specify a regular expression (not very efficient)
    db.tvshows.find({name: {$regex: /Game/}})

$expr -> compare two fields of a document
    eg. a document: {volume:200, target: 120}, {volume: 120, target:300}
    db.collection_name.find({$expr: {$gt: ["$volume", "$target"]}})
    -- only certain operators work with expr (can be looked in documentation)
    -- column names should be enclosed in double quotes and start with $ sign
    -- without $ sign they are just treated has hardcoded strings

    more complex expression (to find all documents where volume>190 and volume-target>=10):
    db.collection_name.find({$expr: {$gt: [{$cond: {if: {$gte: ["$volume", 190], 
    then: {$subtract: ["$volume", 10]}},
    else: "$volume"
    }}, "$target"]}})



